{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "Using the dataset for the risk of heart attack with class imbalance:\n",
    "\n",
    "Create a logistic regression model and measure the performance of it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0    37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "1    41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "2    56.0  1.0  2.0     120.0  236.0  0.0      0.0    178.0    0.0      0.8   \n",
       "3    57.0  0.0  4.0     120.0  354.0  0.0      0.0    163.0    1.0      0.6   \n",
       "4    57.0  1.0  4.0     140.0  192.0  0.0      0.0    148.0    0.0      0.4   \n",
       "..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
       "171  64.0  1.0  4.0     145.0  212.0  0.0      2.0    132.0    0.0      2.0   \n",
       "172  38.0  1.0  1.0     120.0  231.0  0.0      0.0    182.0    1.0      3.8   \n",
       "173  61.0  1.0  4.0     138.0  166.0  0.0      2.0    125.0    1.0      3.6   \n",
       "174  58.0  1.0  4.0     114.0  318.0  0.0      1.0    140.0    0.0      4.4   \n",
       "175  70.0  1.0  4.0     145.0  174.0  0.0      0.0    125.0    1.0      2.6   \n",
       "\n",
       "     slope   ca thal       num  \n",
       "0      3.0  0.0  3.0  negative  \n",
       "1      1.0  0.0  3.0  negative  \n",
       "2      1.0  0.0  3.0  negative  \n",
       "3      1.0  0.0  3.0  negative  \n",
       "4      2.0  0.0  6.0  negative  \n",
       "..     ...  ...  ...       ...  \n",
       "171    2.0  2.0  6.0  positive  \n",
       "172    2.0  0.0  7.0  positive  \n",
       "173    2.0  1.0  3.0  positive  \n",
       "174    3.0  3.0  6.0  positive  \n",
       "175    3.0  0.0  7.0  positive  \n",
       "\n",
       "[176 rows x 14 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('E:/user/Notebooks/data/cleveland-0_vs_4.dat',skiprows = 18,error_bad_lines=False)\n",
    "df.columns =['age', 'sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num'] \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x172f33c5280>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"num\"] = pd.get_dummies(df.num, drop_first=True)\n",
    "sns.countplot(df.num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def create_model(X, y):\n",
    "    X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.20, random_state=111, stratify = y)\n",
    "    \n",
    "    logreg_model = LogisticRegression()\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "\n",
    "    pred_train = logreg_model.predict(X_train)\n",
    "    pred_test = logreg_model.predict(X_test)\n",
    "    \n",
    "    conf_mtx_train = confusion_matrix(y_train, pred_train)\n",
    "    conf_mtx_test = confusion_matrix(y_test, pred_test)\n",
    "    \n",
    "    print(\"Accuracy : {}\\n\".format(logreg_model.score(X_test, y_test)))\n",
    "    \n",
    "    print(\"Train Dataset\")\n",
    "    print(classification_report(y_train, pred_train))\n",
    "    \n",
    "    print(\"Test Dataset\")\n",
    "    print(classification_report(y_test, pred_test))\n",
    "    \n",
    "    return  None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_missing(df, col, name):\n",
    "    if is_numeric_dtype(col):\n",
    "        df[name] = col.fillna(col.median()) \n",
    "for n, c in df.items():\n",
    "        fix_missing(df, c, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ca = df.ca.replace('<null>',1.5)\n",
    "df.thal = df.thal.replace('<null>',5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    163\n",
       "1     13\n",
       "Name: num, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.num.value_counts()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9444444444444444\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       130\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.98       140\n",
      "   macro avg       0.99      0.85      0.91       140\n",
      "weighted avg       0.98      0.98      0.98       140\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        33\n",
      "           1       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.97      0.67      0.74        36\n",
      "weighted avg       0.95      0.94      0.93        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = df['num']\n",
    "X = df.drop('num', axis=1)\n",
    "\n",
    "\n",
    "create_model(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By experimenting with different methods and class ratios; overcome class imbalance, determine the best performing method and class ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    163\n",
       "0    163\n",
       "Name: num, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "normal_shopping = df[df.num == 0]\n",
    "fraudulent_shopping = df[df.num == 1]\n",
    "\n",
    "fraudulent_shopping_upsampled = resample(fraudulent_shopping,\n",
    "                                         replace = True,\n",
    "                                         n_samples = len(normal_shopping),\n",
    "                                         random_state = 111)\n",
    "\n",
    "upsampled_df = pd.concat([normal_shopping, fraudulent_shopping_upsampled])\n",
    "upsampled_df.num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 1.0\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       130\n",
      "           1       0.94      1.00      0.97       130\n",
      "\n",
      "    accuracy                           0.97       260\n",
      "   macro avg       0.97      0.97      0.97       260\n",
      "weighted avg       0.97      0.97      0.97       260\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        33\n",
      "\n",
      "    accuracy                           1.00        66\n",
      "   macro avg       1.00      1.00      1.00        66\n",
      "weighted avg       1.00      1.00      1.00        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = upsampled_df.drop('num', axis=1)\n",
    "y = upsampled_df['num']\n",
    "\n",
    "create_model(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    13\n",
       "0    13\n",
       "Name: num, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_shopping = df[df.num == 0]\n",
    "fraudulent_shopping = df[df.num == 1]\n",
    "\n",
    "fraudulent_shopping_downsampled = resample(normal_shopping,\n",
    "                                         replace = True,\n",
    "                                         n_samples = len(fraudulent_shopping),\n",
    "                                         random_state = 111)\n",
    "\n",
    "downsampled_df = pd.concat([fraudulent_shopping, fraudulent_shopping_downsampled])\n",
    "downsampled_df.num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 1.0\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = downsampled_df.drop('num', axis=1)\n",
    "y = downsampled_df['num']\n",
    "\n",
    "create_model(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "y = df.num\n",
    "X = df.drop('num', axis=1)\n",
    "\n",
    "sm = SMOTE(random_state=27, sampling_strategy=1.0)\n",
    "X_smote, y_smote = sm.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9848484848484849\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       130\n",
      "           1       0.96      0.99      0.98       130\n",
      "\n",
      "    accuracy                           0.98       260\n",
      "   macro avg       0.98      0.98      0.98       260\n",
      "weighted avg       0.98      0.98      0.98       260\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        33\n",
      "           1       0.97      1.00      0.99        33\n",
      "\n",
      "    accuracy                           0.98        66\n",
      "   macro avg       0.99      0.98      0.98        66\n",
      "weighted avg       0.99      0.98      0.98        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_model(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "y = df.num\n",
    "X = df.drop('num', axis=1)\n",
    "\n",
    "ad = ADASYN()\n",
    "X_adasyn, y_adasyn = ad.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9545454545454546\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       130\n",
      "           1       0.96      1.00      0.98       132\n",
      "\n",
      "    accuracy                           0.98       262\n",
      "   macro avg       0.98      0.98      0.98       262\n",
      "weighted avg       0.98      0.98      0.98       262\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        33\n",
      "           1       0.97      0.94      0.95        33\n",
      "\n",
      "    accuracy                           0.95        66\n",
      "   macro avg       0.95      0.95      0.95        66\n",
      "weighted avg       0.95      0.95      0.95        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_model(X_adasyn, y_adasyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "upsampled and down sampled gave best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
